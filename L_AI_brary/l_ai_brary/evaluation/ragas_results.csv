user_input,retrieved_contexts,response,reference,context_precision,context_recall,faithfulness,answer_relevancy
What is the main purpose of the Artificial Intelligence Act?,"['[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] (1) The  purpose  of  this  Regulation  is  to  improve  the  functioning  of  the  internal  market  by\nlaying down a uniform legal framework in particular for the development, the placing on the\nmarket, the putting into service and the use of artificial intelligence systems (AI systems) in\nthe  Union,  in  accordance  with  Union  values,  to  promote  the  uptake  of  human  centric  and\ntrustworthy  artificial  intelligence  (AI)  while  ensuring  a  high  level  of  protection  of  health,\nsafety,  fundamental  rights  as  enshrined  in  the  Charter  of  Fundamental  Rights  of  the\nEuropean  Union  (the  ‘Charter’),  including  democracy,  the  rule  of  law  and  environmental\nprotection, to protect against the harmful effects of AI systems in the Union, and to support\ninnovation.  This  Regulation  ensures  the  free  movement,  cross-border,  of  AI-based  goods\nand  services, \nthe\ndevelopment,  marketing  and  use  of  AI  systems,  unless  explicitly  authorised  by', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] effects for the parties. The use of AI tools can support the decision-making power of judges\nor judicial independence, but should not replace it: the final decision-making must remain\na human-driven activity. The classification of AI systems as high-risk should not, however,\nextend to AI systems intended for purely ancillary administrative activities that do not affect', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] compliance  and  its  correct  enforcement.  Furthermore,  the  wide  implementation  of  AI\nliteracy measures and the introduction of appropriate follow-up actions could contribute to\nimproving working conditions and ultimately sustain the consolidation, and innovation path\nof  trustworthy AI  in  the  Union.  The  European Artificial  Intelligence  Board  (the  ‘Board’)\nshould  support  the  Commission,  to  promote  AI  literacy  tools,  public  awareness  and\nunderstanding of the benefits, risks, safeguards, rights and obligations in relation to the use\nof  AI  systems.  In  cooperation  with  the  relevant  stakeholders,  the  Commission  and  the\nMember States should facilitate the drawing up of voluntary codes of conduct to advance AI\nliteracy among persons dealing with the development, operation and use of AI.', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] (28)Aside from the many beneficial uses of AI, it can also be misused and provide novel and\npowerful tools for manipulative, exploitative and social control practices. Such practices are\nparticularly  harmful  and  abusive  and  should  be  prohibited  because  they  contradict  Union\nvalues of respect for human dignity, freedom, equality, democracy and the rule of law and\nfundamental  rights  enshrined  in  the  Charter,  including  the  right  to  non-discrimination,  to\ndata protection and to privacy and the rights of the child.', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] (12)The notion of ‘AI system’ in this Regulation should be clearly defined and should be closely\naligned with the work of international organisations working on AI to ensure legal certainty,\nfacilitate international convergence and wide acceptance, while providing the flexibility to\naccommodate  the  rapid  technological  developments  in  this  field.  Moreover,  the  definition\nshould  be  based  on  key  characteristics  of  AI  systems  that  distinguish  it  from  simpler\ntraditional software systems or programming approaches and should not cover systems that\nare based on the rules defined solely by natural persons to automatically execute operations.\nA key characteristic of AI systems is their capability to infer. This capability to infer refers\nto the process of obtaining the outputs, such as predictions, content, recommendations, or\ndecisions, which can influence physical and virtual environments, and to a capability of AI', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] activities. As regards national security purposes, the exclusion is justified both by the fact\nthat national security remains the sole responsibility of Member States in accordance with\nArticle  4(2)  TEU  and  by  the  specific  nature  and  operational  needs  of  national  security\nactivities  and  specific  national  rules  applicable  to  those  activities.  Nonetheless,  if  an  AI\nsystem  developed,  placed  on  the  market,  put  into  service  or  used  for  military,  defence  or\nnational  security  purposes  is  used  outside  those  temporarily  or  permanently  for  other\npurposes,  for  example,  civilian  or  humanitarian  purposes,  law  enforcement  or  public\nsecurity purposes, such a system would fall within the scope of this Regulation. In that case,\nthe entity using the AI system for other than military, defence or national security purposes\nshould  ensure  the  compliance  of  the AI  system  with  this  Regulation,  unless  the  system  is']","The main purpose of the Artificial Intelligence Act is not provided in the content. 

Fonte: Non fornito.","The AI Act aims to ensure the smooth functioning of the internal market while protecting fundamental rights, supporting innovation, and fostering trustworthy, human-centric AI in line with EU values",0.8055555555287036,1.0,0.0,0.0
How does the AI Act apply a risk-based approach?,"['[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] (26)In  order  to  introduce  a  proportionate  and  effective  set  of  binding  rules  for  AI  systems,\na clearly defined risk-based approach should be followed. That approach should tailor the\ntype  and  content  of  such  rules  to  the  intensity  and  scope  of  the  risks  that AI  systems  can\ngenerate. It is therefore necessary to prohibit certain unacceptable AI practices, to lay down\nrequirements for high-risk AI systems and obligations for the relevant operators, and to lay\ndown transparency obligations for certain AI systems.', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] detecting fraud in the offering of financial services and for prudential purposes to calculate\ncredit  institutions’  and  insurance  undertakings’  capital  requirements  should  not  be\nconsidered to be high-risk under this Regulation. Moreover, AI systems intended to be used\nfor  risk  assessment  and  pricing  in  relation  to  natural  persons  for  health  and  life  insurance\ncan  also  have  a  significant  impact  on  persons’  livelihood  and  if  not  duly  designed,\ndeveloped  and  used,  can  infringe  their  fundamental  rights  and  can  lead  to  serious\nconsequences for people’s life and health, including financial exclusion and discrimination.\nFinally, AI systems used to evaluate and classify emergency calls by natural persons or to\ndispatch  or  establish  priority  in  the  dispatching  of  emergency  first  response  services,\nincluding by police, firefighters and medical aid, as well as of emergency healthcare patient', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] This calls for a simultaneous and complementary application of the various legislative acts.\nTo ensure consistency and to avoid an unnecessary administrative burden and unnecessary\ncosts,  providers  of  a  product  that  contains  one  or  more  high-risk AI  system,  to  which  the\nrequirements  of  this  Regulation  and  of  the  Union  harmonisation  legislation  based  on  the\nNew  Legislative  Framework  and  listed  in  an  annex  to  this  Regulation  apply,  should  have\nflexibility  with  regard  to  operational  decisions  on  how  to  ensure  compliance  of  a  product\nthat  contains  one  or  more AI  systems  with  all  the  applicable  requirements  of  that  Union\nharmonised  legislation  in  an  optimal  manner.  That  flexibility  could  mean,  for  example', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] be that the AI system is intended to perform a narrow procedural task, such as an AI system\nthat transforms unstructured data into structured data, an AI system that classifies incoming\ndocuments into categories or an AI system that is used to detect duplicates among a large\nnumber  of  applications. Those  tasks  are  of  such  narrow  and  limited  nature  that  they  pose\nonly limited risks which are not increased through the use of an AI system in a context that\nis listed as a high-risk use in an annex to this Regulation. The second condition should be\nthat the task performed by the AI system is intended to improve the result of a previously\ncompleted human activity that may be relevant for the purposes of the high-risk uses listed\nin  an  annex  to  this  Regulation.  Considering  those  characteristics,  the AI  system  provides\nonly an additional layer to a human activity with consequently lowered risk. That condition', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] (65)The  risk-management  system  should  consist  of  a  continuous,  iterative  process  that  is\nplanned  and  run  throughout  the  entire  lifecycle  of  a  high-risk  AI  system.  That  process\nshould  be  aimed  at  identifying  and  mitigating  the  relevant  risks  of AI  systems  on  health,\nsafety and fundamental rights. The risk-management system should be regularly reviewed\nand  updated  to  ensure  its  continuing  effectiveness,  as  well  as  justification  and\ndocumentation  of  any  significant  decisions  and  actions  taken  subject  to  this  Regulation.\nThis  process  should  ensure  that  the  provider  identifies  risks  or  adverse  impacts  and\nimplements  mitigation  measures  for  the  known  and  reasonably  foreseeable  risks  of  AI\nsystems to the health, safety and fundamental rights in light of their intended purpose and\nreasonably  foreseeable  misuse,  including  the  possible  risks  arising  from  the  interaction', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] effects for the parties. The use of AI tools can support the decision-making power of judges\nor judicial independence, but should not replace it: the final decision-making must remain\na human-driven activity. The classification of AI systems as high-risk should not, however,\nextend to AI systems intended for purely ancillary administrative activities that do not affect']","The AI Act applies a risk-based approach by categorizing AI systems into different risk levels based on their potential impact on individuals and society. It identifies four risk categories: unacceptable risk, high risk, limited risk, and minimal risk. Unacceptable-risk AI systems are prohibited, while high-risk systems are subject to strict requirements. Limited and minimal-risk systems face fewer obligations, focusing on transparency and voluntary measures. This approach ensures proportionate regulation tailored to the level of risk posed by AI systems.

**Fonte:** Contenuto fornito dall'utente","The AI Act follows a risk-based approach by prohibiting unacceptable AI practices, setting mandatory requirements for high-risk AI systems, and establishing transparency obligations for certain AI applications",0.9999999999,1.0,0.375,0.9370940258375543
Which AI practices are explicitly prohibited under the Act?,"['[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] provider or the deployer to have the intention to cause significant harm, provided that such\nharm  results  from  the  manipulative  or  exploitative AI-enabled  practices.  The  prohibitions\nfor  such  AI  practices  are  complementary  to  the  provisions  contained  in  Directive\n2005/29/EC  of  the  European  Parliament  and  of  the  Council  (17),  in  particular  unfair\ncommercial  practices  leading  to  economic  or  financial  harms  to  consumers  are  prohibited\nunder all circumstances, irrespective of whether they are put in place through AI systems or\notherwise.  The  prohibitions  of  manipulative  and  exploitative  practices  in  this  Regulation\nshould not affect lawful practices in the context of medical treatment such as psychological', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] monitoring and detecting prohibited behaviour of students during tests should be classified\nas high-risk AI systems, since they may determine the educational and professional course\nof a person’s life and therefore may affect that person’s ability to secure a livelihood. When\nimproperly designed and used, such systems may be particularly intrusive and may violate\nthe right to education and training as well as the right not to be discriminated against and\nperpetuate  historical  patterns  of  discrimination,  for  example  against  women,  certain  age\ngroups,  persons  with  disabilities,  or  persons  of  certain  racial  or  ethnic  origins  or  sexual\norientation.', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] (45)Practices  that  are  prohibited  by  Union  law,  including  data  protection  law,  non-\ndiscrimination law, consumer protection law, and competition law, should not be affected by\nthis Regulation.', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] (28)Aside from the many beneficial uses of AI, it can also be misused and provide novel and\npowerful tools for manipulative, exploitative and social control practices. Such practices are\nparticularly  harmful  and  abusive  and  should  be  prohibited  because  they  contradict  Union\nvalues of respect for human dignity, freedom, equality, democracy and the rule of law and\nfundamental  rights  enshrined  in  the  Charter,  including  the  right  to  non-discrimination,  to\ndata protection and to privacy and the rights of the child.', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] (26)In  order  to  introduce  a  proportionate  and  effective  set  of  binding  rules  for  AI  systems,\na clearly defined risk-based approach should be followed. That approach should tailor the\ntype  and  content  of  such  rules  to  the  intensity  and  scope  of  the  risks  that AI  systems  can\ngenerate. It is therefore necessary to prohibit certain unacceptable AI practices, to lay down\nrequirements for high-risk AI systems and obligations for the relevant operators, and to lay\ndown transparency obligations for certain AI systems.', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] prohibited. In any case, that prohibition does not refer to or touch upon risk analytics that\nare not based on the profiling of individuals or on the personality traits and characteristics\nof individuals, such as AI systems using risk analytics to assess the likelihood of financial\nfraud by undertakings on the basis of suspicious transactions or risk analytic tools to predict\nthe  likelihood  of  the  localisation  of  narcotics  or  illicit  goods  by  customs  authorities,  for\nexample on the basis of known trafficking routes.']","The Act explicitly prohibits AI practices that include:  
1. Subliminal techniques that manipulate a person’s behavior in a manner that could cause harm.  
2. Exploiting vulnerabilities of specific groups due to their age, disability, or other characteristics to significantly distort their behavior in ways that could cause harm.  
3. Social scoring by governments, leading to detrimental treatment of individuals or groups.  
4. Use of AI for real-time biometric identification in public spaces for law enforcement purposes, with exceptions for specific situations such as terrorism or serious crime.  

**Source:** Provided content.","Prohibited practices include manipulative or exploitative techniques that distort human behavior, biometric categorisation revealing sensitive attributes, and social scoring systems that may lead to discrimination or exclusion",0.249999999975,0.3333333333333333,0.4,0.9866054829973282
What requirements apply to high-risk AI systems?,"['[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] (66)Requirements should apply to high-risk AI systems as regards risk management, the quality\nand relevance of data sets used, technical documentation and record-keeping, transparency\nand  the  provision  of  information  to  deployers,  human  oversight,  and  robustness,  accuracy\nand  cybersecurity.  Those  requirements  are  necessary  to  effectively  mitigate  the  risks  for\nhealth,  safety  and  fundamental  rights.  As  no  other  less  trade  restrictive  measures  are\nreasonably available those requirements are not unjustified restrictions to trade.', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] (85)General-purpose  AI  systems  may  be  used  as  high-risk  AI  systems  by  themselves  or  be\ncomponents of other high-risk AI systems. Therefore, due to their particular nature and in\norder to ensure a fair sharing of responsibilities along the AI value chain, the providers of\nsuch systems should, irrespective of whether they may be used as high-risk AI systems as\nsuch  by  other  providers  or  as  components  of  high-risk  AI  systems  and  unless  provided\notherwise under this Regulation, closely cooperate with the providers of the relevant high-\nrisk  AI  systems  to  enable  their  compliance  with  the  relevant  obligations  under  this\nRegulation and with the competent authorities established under this Regulation.', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] ensure full compliance with accessibility requirements, including Directive (EU) 2016/2102\nof the European Parliament and of the Council (38) and Directive (EU) 2019/882. Providers\nshould  ensure  compliance  with  these  requirements  by  design.  Therefore,  the  necessary\nmeasures  should  be  integrated  as  much  as  possible  into  the  design  of  the  high-risk  AI\nsystem.', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] (46)High-risk AI systems should only be placed on the Union market, put into service or used if\nthey  comply  with  certain  mandatory  requirements. Those  requirements  should  ensure  that\nhigh-risk AI systems available in the Union or whose output is otherwise used in the Union\ndo  not  pose  unacceptable  risks  to  important  Union  public  interests  as  recognised  and\nprotected by Union law. On the basis of the New Legislative Framework, as clarified in the\nCommission  notice  ‘The  “Blue  Guide”  on  the  implementation  of  EU  product  rules\n2022’  (20),  the  general  rule  is  that  more  than  one  legal  act  of  Union  harmonisation\nlegislation,  such  as  Regulations  (EU)  2017/745  (21)  and  (EU)  2017/746  (22)  of  the\nEuropean  Parliament  and  of  the  Council  or  Directive  2006/42/EC  of  the  European\nParliament  and  of  the  Council  (23),  may  be  applicable  to  one  product,  since  the  making', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] the achievement of those requirements is demonstrated in the EU declaration of conformity\nor  parts  thereof  issued  under  that  regulation.  To  that  end,  the  assessment  of  the\ncybersecurity risks, associated to a product with digital elements classified as high-risk AI\nsystem  according  to  this  Regulation,  carried  out  under  a  regulation  of  the  European\nParliament  and  of  the  Council  on  horizontal  cybersecurity  requirements  for  products  with\ndigital  elements,  should  consider  risks  to  the  cyber  resilience  of  an AI  system  as  regards\nattempts by unauthorised third parties to alter its use, behaviour or performance, including\nAI  specific  vulnerabilities  such  as  data  poisoning  or  adversarial  attacks,  as  well  as,  as\nrelevant, risks to fundamental rights as required by this Regulation.', '[source:C:\\Users\\QH745LV\\Documents\\ProgettoFinale_Gruppo5_AIAcademy\\L_AI_brary\\l_ai_brary\\streamlit_frontend\\..\\knowledge_base\\Short AI Act.pdf] (72)To  address  concerns  related  to  opacity  and  complexity  of  certain  AI  systems  and  help\ndeployers to fulfil their obligations under this Regulation, transparency should be required\nfor high-risk AI systems before they are placed on the market or put it into service. High-\nrisk AI systems should be designed in a manner to enable deployers to understand how the\nAI  system  works,  evaluate  its  functionality,  and  comprehend  its  strengths  and  limitations.\nHigh-risk  AI  systems  should  be  accompanied  by  appropriate  information  in  the  form  of\ninstructions  of  use.  Such  information  should  include  the  characteristics,  capabilities  and\nlimitations  of  performance  of  the AI  system.  Those  would  cover  information  on  possible\nknown  and  foreseeable  circumstances  related  to  the  use  of  the  high-risk  AI  system,\nincluding  deployer  action  that  may  influence  system  behaviour  and  performance,  under']","The requirements for high-risk AI systems include ensuring high standards of safety, accuracy, cybersecurity, and transparency. These systems must be designed to avoid discriminatory outcomes and provide clear documentation, including information on their purpose and functioning. 

**Source:** CONTENUTO","High-risk AI systems must comply with strict requirements to protect health, safety, and fundamental rights, including robust risk management, transparency, documentation, and conformity assessments before being placed on the market.",0.691666666649375,1.0,0.75,0.9853546490956465
